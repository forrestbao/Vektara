{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the unofficial Python SDK for [Vectara](https://vectara.com)'s RAG platform\n",
    "\n",
    "For questions, ask forrest@vectara.com "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file testdoc already exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-21 21:13:16 URL:https://www.cs.jhu.edu/~jason/papers/mei+al.icml20.pdf [2087657/2087657] -> \"testdoc/neural_datalog_through_time.pdf\" [1]\n",
      "2023-11-21 21:13:16 URL:https://docs.vectara.com/assets/files/vectara_employee_handbook-4524365135dc70a59977373c37601ad1.pdf [53575/53575] -> \"testdoc/vectara.pdf\" [1]\n",
      "2023-11-21 21:13:16 URL:https://raw.githubusercontent.com/TexteaInc/funix-doc/main/Reference.md [35949/35949] -> \"testdoc/funix.md\" [1]\n",
      "2023-11-21 21:13:17 URL:https://raw.githubusercontent.com/codepod-io/codepod.io/main/docs/3-manual/README.md [7451/7451] -> \"codepod.md\" [1]\n"
     ]
    }
   ],
   "source": [
    "# Get some test data \n",
    "!mkdir testdoc \n",
    "!wget https://www.cs.jhu.edu/~jason/papers/mei+al.icml20.pdf -O testdoc/neural_datalog_through_time.pdf -nv \n",
    "!wget https://docs.vectara.com/assets/files/vectara_employee_handbook-4524365135dc70a59977373c37601ad1.pdf -O testdoc/vectara.pdf -nv \n",
    "!wget https://raw.githubusercontent.com/TexteaInc/funix-doc/main/Reference.md -O testdoc/funix.md -nv \n",
    "!wget https://raw.githubusercontent.com/codepod-io/codepod.io/main/docs/3-manual/README.md -O codepod.md -nv\n",
    "# !wget https://raw.githubusercontent.com/tangxyw/RecSysPapers/main/Calibration/Posterior%20Probability%20Matters%20-%20Doubly-Adaptive%20Calibration%20for%20Neural%20Predictions%20in%20Online%20Advertising.pdf -O testdoc/Calibration.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a client object \n",
    "\n",
    "By default, the constructor will look for the following environment variables:\n",
    "* VECTARA_CUSTOMER_ID\n",
    "* VECTARA_CLIENT_ID\n",
    "* VECTARA_CLIENT_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bearer/JWT token generated. It will expire in 30 minutes. To-regenerate, please call acquire_jwt_token(). \n"
     ]
    }
   ],
   "source": [
    "# client = vectara.vectara() # default to credentials in environment variables\n",
    "\n",
    "## OR import from a python file called keys.py\n",
    "from keys import VECTARA_CUSTOMER_ID, VECTARA_CLIENT_ID, VECTARA_CLIENT_SECRET\n",
    "client = vectara.vectara(VECTARA_CUSTOMER_ID, VECTARA_CLIENT_ID, VECTARA_CLIENT_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New corpus created, corpus ID is: 3\n"
     ]
    }
   ],
   "source": [
    "corpus_id = client.create_corpus(\"test_corpus\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reset Corpus (when needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resetting corpus 3 successful. \n"
     ]
    }
   ],
   "source": [
    "corpus_id = 3 # manual set here \n",
    "client.reset_corpus(corpus_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add files to a corpus\n",
    "\n",
    "You can use the `upload()` method to upload a file, a list of files, or a folder to a corpus. The `upload()` method automatically detects the type of file source to switch between the three methods below.\n",
    "* `upload_file()`: upload a single file\n",
    "* `upload_files()`: upload a list of files\n",
    "* `upload_folder()`: upload all files in a folder\n",
    "\n",
    "Of course, if you are very sure about what you are doing, you can also use the three methods above directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading files from folder: ./testdoc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:   0%|          | 0/3 [00:00<?, ?it/s, ./testdoc\\funix.md]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading..../testdoc\\funix.md "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:  33%|███▎      | 1/3 [00:02<00:04,  2.14s/it, ./testdoc\\neural_datalog_through_time.pdf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n",
      "Uploading..../testdoc\\neural_datalog_through_time.pdf "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...:  67%|██████▋   | 2/3 [00:09<00:05,  5.39s/it, ./testdoc\\vectara.pdf]                    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n",
      "Uploading..../testdoc\\vectara.pdf "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading...: 100%|██████████| 3/3 [00:12<00:00,  4.05s/it, ./testdoc\\vectara.pdf]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "client.upload(corpus_id, './testdoc', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query to a corpus and beautifully display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "To rearrange objects, you can follow these steps: Firstly, you can change the order and orientation of objects using the \"direction\" attribute in a Funix decorator[3]. Additionally, you can recompute the embeddings of objects in parallel, either within strongly connected components or for selected past events[2][4]. It is important to visit the components in topologically sorted order to ensure the best available embeddings of upstream nodes[5]. By applying these techniques, you can effectively rearrange objects.\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **neural_datalog_through_time.pdf** (matchness=0.65684634):\n",
       "  _...This method recomputes all embeddings in parallel,\n",
       "and repeats this for some number of iterations...._\n",
       "\n",
       "2. From document **neural_datalog_through_time.pdf** (matchness=0.6553048):\n",
       "  _...Within each strongly connected component C, ini-\n",
       "tialize the embeddings to 0 and then recompute them in\n",
       "parallel for |C| iterations...._\n",
       "\n",
       "3. From document **funix.md** (matchness=0.65107906):\n",
       "  _...You can change their order and orientation using the \"direction\" attribute in a Funix decorator...._\n",
       "\n",
       "4. From document **neural_datalog_through_time.pdf** (matchness=0.6380951):\n",
       "  _...® Embeddings of entities and relations\n",
       "that reﬂect selected past events (§2.4 and §2.6)...._\n",
       "\n",
       "5. From document **neural_datalog_through_time.pdf** (matchness=0.6360733):\n",
       "  _...In the general case, visiting the com-\n",
       "ponents in topologically sorted order means that we wait to\n",
       "work on component C until its strictly upstream nodes have\n",
       "“converged,” so that the limited iterations on C make use of\n",
       "the best available embeddings of the upstream nodes...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"What should I do to rearrange objects?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "You can bring friends to the office, but there may be some peculiarities to this policy that you must understand [2]. Some workplaces even have special events like \"Furry Friend Fridays\" where you can introduce your pets via video conference [1]. Additionally, there are team-building adventures and exotic pet interactions designed to enhance communication and inject fun into the workplace [3]. Bringing pets can add a colorful flair to team meetings [4]. However, it's important to note that the search results provided limited information, so it's advisable to check with your specific workplace policies for more details.\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **vectara.pdf** (matchness=0.6796313):\n",
       "  _...monthly \"Furry Friend Fridays\" where you can introduce your pets via video conference...._\n",
       "\n",
       "2. From document **vectara.pdf** (matchness=0.63029546):\n",
       "  _...However, before you bring in your pet parrot or rescue raven, there are some\n",
       "peculiarities to this policy that you must understand...._\n",
       "\n",
       "3. From document **vectara.pdf** (matchness=0.62800384):\n",
       "  _...The Team-building Adventures: From velociraptor training simulations to bear dance-offs, our\n",
       "exotic pet interactions are designed to build teamwork, enhance communication, and inject fun\n",
       "into the workplace...._\n",
       "\n",
       "4. From document **vectara.pdf** (matchness=0.6266819):\n",
       "  _...Plus, they add a colorful ﬂair to team meetings...._\n",
       "\n",
       "5. From document **vectara.pdf** (matchness=0.6225399):\n",
       "  _...We appreciate the sentiment, and we're sure your furry\n",
       "friends are delightful...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"Can I bring friends to the office?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True, format='markdown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example query 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query successful. \n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Here is the answer\n",
       "The returned results did not contain sufficient information to be summarized into a useful answer for your query. Please try a different search or restate your query differently.\n",
       "\n",
       "### References:\n",
       "    \n",
       "1. From document **neural_datalog_through_time.pdf** (matchness=0.684738):\n",
       "  _...We take λh(t) to be the\n",
       "(Poisson) intensity of h at time t:  that is, it models the\n",
       "limit as dt → 0+ of the expected rate of h on the interval\n",
       "[t, t + dt) (i.e., the expected number of occurrences of h\n",
       "divided by dt)...._\n",
       "\n",
       "2. From document **neural_datalog_through_time.pdf** (matchness=0.6802496):\n",
       "  _...In the continuous-time case, we evaluate (8) at\n",
       "                rm\n",
       "time s to obtain [h]<-   ∈ R7Dh (so Wr needs to have more\n",
       "                                                  rm\n",
       "rows), and accordingly obtain 7 vectors in (0, 1)Dh,..._\n",
       "\n",
       "3. From document **neural_datalog_through_time.pdf** (matchness=0.67772794):\n",
       "  _...We then set (f ; i; z) =def\n",
       "σ([h]<-  )...._\n",
       "\n",
       "4. From document **funix.md** (matchness=0.6768694):\n",
       "  _...There will be a radio box on the front end for the user to switch between the two display options at any time, and the JSON Viewer will be used by default...._\n",
       "\n",
       "5. From document **funix.md** (matchness=0.6706363):\n",
       "  _...If sessions are not properly maintained, you can use two Funix functions to manually set and get a session-level global variable...._\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "answer = client.query(corpus_id, \"How to set the frequency?\")\n",
    "_ = vectara.post_process_query_result(answer, jupyter_display=True, format='markdown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
